{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5437b69a-1d18-402c-aff2-8435358d9326",
   "metadata": {},
   "source": [
    "### Setup "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cff2d6-7069-46ca-989b-4d901ebdd3f3",
   "metadata": {},
   "source": [
    "# INTERACTIVE EXAMPLE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808c9e3b-e793-46c3-9599-1a473069c5a6",
   "metadata": {},
   "source": [
    "**Note:** for running the example we need at least a `ml.m5.large` instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c3308c-3e63-42ef-bb47-a9d76e889d0c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaed9bb5-5ddf-4586-8e96-4c387622eebf",
   "metadata": {},
   "source": [
    "## Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd56ed5-b069-4219-9cdf-0a236dbd2ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9178a27-4248-4b3c-89e4-e31c36aefa97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1bb93676-2530-4351-9e11-104bac7f7e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade huggingface_hub --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a35e349-2abb-4e4e-a5a1-836f62a47d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade transformers\n",
    "!pip install --upgrade accelerate\n",
    "!pip install --upgrade tokenizers\n",
    "!pip install --upgrade peft\n",
    "!pip install --upgrade bitsandbytes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "749789be-2828-4e06-bfef-392c04847c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install sentence_transformers --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "149fd34f-1682-4c5b-a8a2-fd944fb14298",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install rouge  --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e64c940c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f812db79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: unstructured[all-docs] in /opt/conda/lib/python3.10/site-packages (0.11.2)\n",
      "Requirement already satisfied: chardet in /opt/conda/lib/python3.10/site-packages (from unstructured[all-docs]) (5.2.0)\n",
      "Requirement already satisfied: filetype in /opt/conda/lib/python3.10/site-packages (from unstructured[all-docs]) (1.2.0)\n",
      "Requirement already satisfied: python-magic in /opt/conda/lib/python3.10/site-packages (from unstructured[all-docs]) (0.4.27)\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from unstructured[all-docs]) (4.9.3)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from unstructured[all-docs]) (3.8.1)\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from unstructured[all-docs]) (0.9.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from unstructured[all-docs]) (2.28.2)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from unstructured[all-docs]) (4.12.2)\n",
      "Requirement already satisfied: emoji in /opt/conda/lib/python3.10/site-packages (from unstructured[all-docs]) (2.8.0)\n",
      "Requirement already satisfied: dataclasses-json in /opt/conda/lib/python3.10/site-packages (from unstructured[all-docs]) (0.6.3)\n",
      "Requirement already satisfied: python-iso639 in /opt/conda/lib/python3.10/site-packages (from unstructured[all-docs]) (2023.6.15)\n",
      "Requirement already satisfied: langdetect in /opt/conda/lib/python3.10/site-packages (from unstructured[all-docs]) (1.0.9)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from unstructured[all-docs]) (1.23.5)\n",
      "Requirement already satisfied: rapidfuzz in /opt/conda/lib/python3.10/site-packages (from unstructured[all-docs]) (3.5.2)\n",
      "Requirement already satisfied: backoff in /opt/conda/lib/python3.10/site-packages (from unstructured[all-docs]) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from unstructured[all-docs]) (4.8.0)\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from unstructured[all-docs]) (1.16.0)\n",
      "Collecting python-docx>=1.1.0 (from unstructured[all-docs])\n",
      "  Downloading python_docx-1.1.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting xlrd (from unstructured[all-docs])\n",
      "  Downloading xlrd-2.0.1-py2.py3-none-any.whl (96 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.5/96.5 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting onnx (from unstructured[all-docs])\n",
      "  Downloading onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
      "Collecting pypdf (from unstructured[all-docs])\n",
      "  Downloading pypdf-3.17.1-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from unstructured[all-docs]) (3.1)\n",
      "Collecting msg-parser (from unstructured[all-docs])\n",
      "  Downloading msg_parser-1.2.0-py2.py3-none-any.whl (101 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from unstructured[all-docs]) (2.0.1)\n",
      "Requirement already satisfied: pdfminer.six in /opt/conda/lib/python3.10/site-packages (from unstructured[all-docs]) (20221105)\n",
      "Collecting markdown (from unstructured[all-docs])\n",
      "  Downloading Markdown-3.5.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting unstructured-inference==0.7.15 (from unstructured[all-docs])\n",
      "  Downloading unstructured_inference-0.7.15-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: pdf2image in /opt/conda/lib/python3.10/site-packages (from unstructured[all-docs]) (1.16.3)\n",
      "Collecting pypandoc (from unstructured[all-docs])\n",
      "  Downloading pypandoc-1.12-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting openpyxl (from unstructured[all-docs])\n",
      "  Downloading openpyxl-3.1.2-py2.py3-none-any.whl (249 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.0/250.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pikepdf in /opt/conda/lib/python3.10/site-packages (from unstructured[all-docs]) (8.7.1)\n",
      "Collecting unstructured.pytesseract>=0.3.12 (from unstructured[all-docs])\n",
      "  Downloading unstructured.pytesseract-0.3.12-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting python-pptx<=0.6.23 (from unstructured[all-docs])\n",
      "  Downloading python_pptx-0.6.23-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting layoutparser[layoutmodels,tesseract] (from unstructured-inference==0.7.15->unstructured[all-docs])\n",
      "  Downloading layoutparser-0.3.4-py3-none-any.whl (19.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting python-multipart (from unstructured-inference==0.7.15->unstructured[all-docs])\n",
      "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m747.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from unstructured-inference==0.7.15->unstructured[all-docs]) (0.19.4)\n",
      "Requirement already satisfied: opencv-python!=4.7.0.68 in /opt/conda/lib/python3.10/site-packages (from unstructured-inference==0.7.15->unstructured[all-docs]) (4.7.0)\n",
      "Collecting onnxruntime<1.16 (from unstructured-inference==0.7.15->unstructured[all-docs])\n",
      "  Downloading onnxruntime-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: transformers>=4.25.1 in /opt/conda/lib/python3.10/site-packages (from unstructured-inference==0.7.15->unstructured[all-docs]) (4.35.2)\n",
      "Requirement already satisfied: Pillow>=3.3.2 in /opt/conda/lib/python3.10/site-packages (from python-pptx<=0.6.23->unstructured[all-docs]) (10.1.0)\n",
      "Collecting XlsxWriter>=0.5.7 (from python-pptx<=0.6.23->unstructured[all-docs])\n",
      "  Downloading XlsxWriter-3.1.9-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/conda/lib/python3.10/site-packages (from unstructured.pytesseract>=0.3.12->unstructured[all-docs]) (23.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->unstructured[all-docs]) (2.5)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json->unstructured[all-docs]) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json->unstructured[all-docs]) (0.9.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from langdetect->unstructured[all-docs]) (1.16.0)\n",
      "Collecting olefile>=0.46 (from msg-parser->unstructured[all-docs])\n",
      "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk->unstructured[all-docs]) (8.1.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk->unstructured[all-docs]) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk->unstructured[all-docs]) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk->unstructured[all-docs]) (4.65.0)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /opt/conda/lib/python3.10/site-packages (from onnx->unstructured[all-docs]) (3.20.3)\n",
      "Collecting et-xmlfile (from openpyxl->unstructured[all-docs])\n",
      "  Downloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->unstructured[all-docs]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->unstructured[all-docs]) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->unstructured[all-docs]) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from pdfminer.six->unstructured[all-docs]) (3.1.0)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /opt/conda/lib/python3.10/site-packages (from pdfminer.six->unstructured[all-docs]) (40.0.1)\n",
      "Requirement already satisfied: Deprecated in /opt/conda/lib/python3.10/site-packages (from pikepdf->unstructured[all-docs]) (1.2.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->unstructured[all-docs]) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->unstructured[all-docs]) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->unstructured[all-docs]) (2023.5.7)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=36.0.0->pdfminer.six->unstructured[all-docs]) (1.15.1)\n",
      "Requirement already satisfied: coloredlogs in /opt/conda/lib/python3.10/site-packages (from onnxruntime<1.16->unstructured-inference==0.7.15->unstructured[all-docs]) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime<1.16->unstructured-inference==0.7.15->unstructured[all-docs]) (23.5.26)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from onnxruntime<1.16->unstructured-inference==0.7.15->unstructured[all-docs]) (1.11.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers>=4.25.1->unstructured-inference==0.7.15->unstructured[all-docs]) (3.12.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.25.1->unstructured-inference==0.7.15->unstructured[all-docs]) (6.0.1)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.25.1->unstructured-inference==0.7.15->unstructured[all-docs]) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.25.1->unstructured-inference==0.7.15->unstructured[all-docs]) (0.4.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->unstructured-inference==0.7.15->unstructured[all-docs]) (2023.5.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured[all-docs]) (1.0.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.15->unstructured[all-docs]) (1.10.1)\n",
      "Collecting iopath (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.15->unstructured[all-docs])\n",
      "  Using cached iopath-0.1.10-py3-none-any.whl\n",
      "Collecting pdfplumber (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.15->unstructured[all-docs])\n",
      "  Downloading pdfplumber-0.10.3-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.15->unstructured[all-docs]) (2.0.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.15->unstructured[all-docs]) (0.15.1)\n",
      "Collecting effdet (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.15->unstructured[all-docs])\n",
      "  Downloading effdet-0.4.1-py3-none-any.whl.metadata (33 kB)\n",
      "Collecting pytesseract (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.15->unstructured[all-docs])\n",
      "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->unstructured[all-docs]) (2.21)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/conda/lib/python3.10/site-packages (from coloredlogs->onnxruntime<1.16->unstructured-inference==0.7.15->unstructured[all-docs]) (10.0)\n",
      "Collecting timm>=0.9.2 (from effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.15->unstructured[all-docs])\n",
      "  Downloading timm-0.9.12-py3-none-any.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m941.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pycocotools>=2.0.2 (from effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.15->unstructured[all-docs])\n",
      "  Downloading pycocotools-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting omegaconf>=2.0 (from effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.15->unstructured[all-docs])\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.15->unstructured[all-docs]) (3.1.2)\n",
      "Collecting portalocker (from iopath->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.15->unstructured[all-docs])\n",
      "  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting pypdfium2>=4.18.0 (from pdfplumber->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.15->unstructured[all-docs])\n",
      "  Downloading pypdfium2-4.24.0-py3-none-manylinux_2_17_x86_64.whl.metadata (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.6/45.6 kB\u001b[0m \u001b[31m740.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->onnxruntime<1.16->unstructured-inference==0.7.15->unstructured[all-docs]) (1.3.0)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from omegaconf>=2.0->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.15->unstructured[all-docs])\n",
      "  Using cached antlr4_python3_runtime-4.9.3-py3-none-any.whl\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.15->unstructured[all-docs]) (3.7.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.15->unstructured[all-docs]) (2.1.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.15->unstructured[all-docs]) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.15->unstructured[all-docs]) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.15->unstructured[all-docs]) (4.39.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.15->unstructured[all-docs]) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.15->unstructured[all-docs]) (3.0.9)\n",
      "Downloading unstructured_inference-0.7.15-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_docx-1.1.0-py3-none-any.whl (239 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.6/239.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_pptx-0.6.23-py3-none-any.whl (471 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading unstructured.pytesseract-0.3.12-py3-none-any.whl (14 kB)\n",
      "Downloading Markdown-3.5.1-py3-none-any.whl (102 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading pypandoc-1.12-py3-none-any.whl (20 kB)\n",
      "Downloading pypdf-3.17.1-py3-none-any.whl (277 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m277.6/277.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading onnxruntime-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading XlsxWriter-3.1.9-py3-none-any.whl (154 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading effdet-0.4.1-py3-none-any.whl (112 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.5/112.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pdfplumber-0.10.3-py3-none-any.whl (48 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.0/49.0 kB\u001b[0m \u001b[31m826.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pycocotools-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (426 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.2/426.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pypdfium2-4.24.0-py3-none-manylinux_2_17_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading timm-0.9.12-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: antlr4-python3-runtime, XlsxWriter, xlrd, unstructured.pytesseract, python-multipart, python-docx, pytesseract, pypdfium2, pypdf, pypandoc, portalocker, onnx, omegaconf, olefile, markdown, et-xmlfile, python-pptx, openpyxl, onnxruntime, msg-parser, iopath, pycocotools, timm, pdfplumber, layoutparser, effdet, unstructured-inference\n",
      "  Attempting uninstall: onnxruntime\n",
      "    Found existing installation: onnxruntime 1.16.3\n",
      "    Uninstalling onnxruntime-1.16.3:\n",
      "      Successfully uninstalled onnxruntime-1.16.3\n",
      "Successfully installed XlsxWriter-3.1.9 antlr4-python3-runtime-4.9.3 effdet-0.4.1 et-xmlfile-1.1.0 iopath-0.1.10 layoutparser-0.3.4 markdown-3.5.1 msg-parser-1.2.0 olefile-0.47 omegaconf-2.3.0 onnx-1.15.0 onnxruntime-1.15.1 openpyxl-3.1.2 pdfplumber-0.10.3 portalocker-2.8.2 pycocotools-2.0.7 pypandoc-1.12 pypdf-3.17.1 pypdfium2-4.24.0 pytesseract-0.3.10 python-docx-1.1.0 python-multipart-0.0.6 python-pptx-0.6.23 timm-0.9.12 unstructured-inference-0.7.15 unstructured.pytesseract-0.3.12 xlrd-2.0.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U unstructured --quiet\n",
    "!pip install pdf2image  --quiet\n",
    "!pip install pdfminer  --quiet\n",
    "!pip install pdfminer.six  --quiet\n",
    "!pip install -U \"unstructured[all-docs]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "754e3245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install opencv-python-headless --quiet #required for cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da133f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.27.132 requires PyYAML<5.5,>=3.10, but you have pyyaml 6.0.1 which is incompatible.\n",
      "sagemaker 2.154.0 requires importlib-metadata<5.0,>=1.4.0, but you have importlib-metadata 6.9.0 which is incompatible.\n",
      "sagemaker 2.154.0 requires PyYAML==5.4.1, but you have pyyaml 6.0.1 which is incompatible.\n",
      "spacy 3.5.2 requires typer<0.8.0,>=0.3.0, but you have typer 0.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install chromadb  --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428e2cf0",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df06b4ff-16d9-458a-9b90-11ec2eb749cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef6b9cfa-44ff-4105-b885-2ebdbc55cc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73791d6e-8b0d-4ad2-aa8d-a442b3e5f991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8226a793-ea59-4608-943b-645365548a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import UnstructuredPDFLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.text_splitter import NLTKTextSplitter\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b895235-b3e9-4db0-918b-b9bd1308d481",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup the llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42188b0f-a4ab-4099-aa44-912909914d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "from transformers import TextStreamer, pipeline\n",
    "from transformers import (AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig)\n",
    "import torch\n",
    "model_path = \"harpomaxx/Llama-2-13b-hf-juris-adapter\"\n",
    "tokenizer_path = \"harpomaxx/Llama-2-13b-hf-juris-adapter\"\n",
    "\n",
    "#model_path = \"meta-llama/Llama-2-13b-hf\"\n",
    "#tokenizer_path = \"meta-llama/Llama-2-13b-hf\"\n",
    "\n",
    "#model_path = \"HuggingFaceH4/zephyr-7b-beta\"\n",
    "#tokenizer_path = \"HuggingFaceH4/zephyr-7b-beta\"\n",
    "\n",
    "\n",
    "\n",
    "#model_path = \"/home/harpo/CEPH/LLM-models/Llama-2-7b-chat-hf/\"\n",
    "#tokenizer_path = \"/home/harpo/CEPH/LLM-models/Llama-2-7b-chat-hf/\"\n",
    "\n",
    "quantize = True\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "#load_in_8bit=True\n",
    "load_in_4bit=True,\n",
    "bnb_4bit_quant_type=\"nf4\",\n",
    "bnb_4bit_compute_dtype= getattr(torch, \"float16\"),\n",
    "bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "quantization_config = bnb_config if quantize else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b3a4a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "quantization_config = bnb_config if quantize else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad79139f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "789fdeec3d2447d28aeeb43fd03ff8a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_config.json:   0%|          | 0.00/511 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5e1c7461be343aa9d5dcceb24b8ea0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_path,\n",
    "            quantization_config=quantization_config,\n",
    "            device_map =\"auto\",\n",
    "            #device_map={\"\": 0},\n",
    "            trust_remote_code=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca09a635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0098117e27c4900adb83158d123a985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.71k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b866d18959e14a858bbb981a32f36dd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5223e3ab4e04ee3ad12d87e7feb1138",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "995b10f2ca694891b9b33ca40471cab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/437 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "tok = AutoTokenizer.from_pretrained(tokenizer_path,\n",
    "            trust_remote_code=True,\n",
    "            #device_map={\"\": 0}\n",
    "            device_map=\"auto\"\n",
    "            )\n",
    "#model.config.pad_token_id = tok.pad_token_id = 0  # unk\n",
    "#model.config.bos_token_id = 1\n",
    "#model.config.eos_token_id = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d8bf9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "streamer = TextStreamer(tok, skip_prompt=True)\n",
    "generator = pipeline('text-generation',\n",
    "                         model=model,\n",
    "                         tokenizer=tok,\n",
    "                         #streamer=streamer,\n",
    "                         return_full_text=False,\n",
    "                         do_sample=True,\n",
    "                         temperature = 0.1,\n",
    "                         #early_stopping= True,\n",
    "                         #num_beams =1 ,\n",
    "                         no_repeat_ngram_size= 3,\n",
    "\n",
    "                         #max_length=100\n",
    "                         max_new_tokens=500 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a144ea0-da0d-41e3-95cb-808bffa09114",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Test the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d5cfdaf-da73-4229-af39-a8d5c01ccdcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Aquí se presenta un ejemplo del sumario que se podría presentar ante la Corte de Mando de Mendiola en un caso de derecho Laboral:\n",
      "\n",
      "**Caso:**\n",
      "\n",
      "Nombre: Maria del Carmen Lopez\n",
      "\n",
      "Edad: 45 años\n",
      "\n",
      "Profesion: Administradora\n",
      "\n",
      "Cargo: Secretaria Administrativa\n",
      "\n",
      "Fecha de inicio: 2018\n",
      "\n",
      "Descripción del caso:\n",
      "- Maria del carmen Lpez fue despuesada de su cargo laboral sin previo aviso legal, ni con la correspondiente indemnización. \n",
      "- La actora alega que el despido fue arbitrario y discriminatorio por su edad y condicion de mujer.\n",
      "- Se solicita la reinstalación en su cargo, indemnisación por despido injustificado, inhabilitación del directorio y costas.\n",
      "\n",
      "Hechos del caso\n",
      "\n",
      "- En 27 de febrero de 2o017 Maria del Camen Lopezz fue contratada como secretaria administrativa en la sociedad \"La Voz de Mendez\" S.A.\n",
      "Desde su ingreso la actora se destacó por su buen desempeño laboral, se encargó de la atención a los trabajadores, la contabilidad, la gestión de la secretaría, entre otras tareas. 11 de mayo de 019: El directorio de la socieda decide despedir a la actura sin prevío aviso, sin fundamentar sus razones. 06 de Junio de 19 : La actura interpone recurso extraordinario de inconstitucionalidad contra la sentencia de primera instancia. 22 de Julio de '19 - La actrua interpuso recursios de inhibilitación y de indemnicar contra el directorio. 31 de Jullio de 9: La actua interpuse recuroso de incapacidad contra el abogado.\n",
      "03 de Agosto de 3: La recurosa interpusa recuriso de indefendencia contra el jefe de la seccion primera del\n"
     ]
    }
   ],
   "source": [
    "_ = generator(\"[INST] Generar un ejemplo de un sumario de la corte de Mendoza en derecho laboral. [/INST]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b7f480",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4dd17fd-dc5e-442e-924e-9306c1c69870",
   "metadata": {},
   "source": [
    "## Setup SBERT for calculating embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20e17753-4cf8-429d-b2dc-f5c1156b5662",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fccd548-a93e-4421-9f74-962e22791928",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e49208-4404-4c98-ae93-7d9b30aa644d",
   "metadata": {},
   "source": [
    "## Setup LLM for LANGCHAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebc5a128",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "llm = HuggingFacePipeline(\n",
    "    pipeline= generator,\n",
    "    #model_kwargs={\"temperature\": 0, \"max_length\": 4096,\"max_new_tokens\":4096},\n",
    "    #callback_manager=callback_manager\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e6262a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm(\"[INST] Generar un ejemplo de un sumario de la corte de Mendoza en derecho laboral. [/INST]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56d555f",
   "metadata": {},
   "source": [
    "# INTERACTIVE EXAMPLE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910d36d3-b87c-43fc-bd88-3409cc5d5536",
   "metadata": {},
   "source": [
    "## Load a PDF and calculate the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "529dc29d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebd0f465-6390-48ac-bcfe-cb48d004529a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = UnstructuredPDFLoader(\"/home/harpo/git-repos/JurisGPT/rawdata/laboral/sumarios/fallos/10000003368.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be11de5-fd70-43d4-ac9b-df81de1d6aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorstoreIndexCreator(embedding=embedding).from_loaders([loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c03c5de-76d1-4694-9560-b0b736f37a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.vectorstore.delete_collection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd872ef9-0a6a-41ba-93e9-36a9eb52e89a",
   "metadata": {},
   "source": [
    "## Ask LLM to summarize each section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3784c955-4e79-4cc1-934b-f69f91174623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "La sección \"Antecedes\" de la sentencia se enfoca en la conformación de la lealtad legislativa en el ámbito local y nacional. Se reconoce la adherencia de las provincías a la normativad nacional en materia de seguridad y riesgos de trabajo, mediante la sanación de leyes locales que delegan competencias a la administración nacional. Sin embargo, se destaca que la adscripción no fue total, ya que se reconocieron competencias no delegables a la nación. Además, se invita al resto de provincianos y a Buenos Aires para adherirse a la misma normativa. En resumen, se trata de la conformción de una lealtud legislativa que busca garantizar la segurança y bienestar del trabajador en el marco de la aplicación de las leyes nacionales.</s>\n",
      "\n",
      "\n",
      "La sección \"Antecedes\" de la sentencia se enfoca en la conformación de la lealtad legislativa en el ámbito local y nacional. Se reconoce la adherencia de las provincías a la normativad nacional en materia de seguridad y riesgos de trabajo, mediante la sanación de leyes locales que delegan competencias a la administración nacional. Sin embargo, se destaca que la adscripción no fue total, ya que se reconocieron competencias no delegables a la nación. Además, se invita al resto de provincianos y a Buenos Aires para adherirse a la misma normativa. En resumen, se trata de la conformción de una lealtud legislativa que busca garantizar la segurança y bienestar del trabajador en el marco de la aplicación de las leyes nacionales.\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\" \n",
    "<s>[INST]<<SYS>>\n",
    "Think after answer. Your answer should be in spanish. Not english.\n",
    "<</SYS>>\n",
    "Eres un miembro de la corte Suprema de Mendoza en Argentina. Tienes que escribir un sumario de la seccion 'Antecedentes' de una sentencia de la corte. Escribe tu respuesta español en no menos de 150 palabras: \n",
    "[/INSTR]\n",
    "\"\"\"\n",
    "\n",
    "summary_ant = (index.query(query,llm=llm))\n",
    "print(summary_ant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1f416496-59b2-42cc-b2a0-fe4e5f43b554",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "<s>[INST]<<SYS>>\n",
    "Think after answer. Your answer should be in spanish. Not english.\n",
    "<</SYS>> \n",
    "Eres un miembro de la corte suprema de Mendoza en Argentina. Tienes que escribir un sumario de la seccion 'Sobre la primera cuestion' de una sentencia de la corte. Escribe tu respuesta en español en no menos de 150 palabras:\n",
    "[/INSTR]\n",
    "\"\"\"\n",
    "summary_1 = (index.query(query,llm=llm))\n",
    "print(summary_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1c04e2-0428-4bab-a89a-c6ab90eaccc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Eres un miembro de la corte suprema de Mendoza en Argentina. Tienes que escribir un resume de la seccion 'Sobre la segunda cuestion' de una sentencia de la corte. Escribe tu respuesta en no menos de 150 palabras:\"\n",
    "summary_2 = (index.query(query,llm=llm))\n",
    "print(summary_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1fe3db-5a0c-4ee5-8de9-d6fbaeca81bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Eres un miembro de la corte suprema de Mendoza en Argentina. Tienes que escribir un resume de la seccion 'Sobre la tercera cuestion' de una sentencia de la corte. Escribe tu respuesta en no menos de 150 palabras:\"\n",
    "summary_3 = (index.query(query,llm=llm))\n",
    "print(summary_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a6a669-ece7-46c6-9afa-2eb1a3eac2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Eres un miembro de la corte suprema de Mendoza en Argentina. Tienes que escribir un resumen de la seccion 'Resuelve' de una sentencia de la corte. Escribe tu respuesta en no menos de 150 palabras:\"\n",
    "summary_res = (index.query(query,llm=llm))\n",
    "print(summary_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06501739-8ae9-4c07-a3e5-c2a4503522b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"Eres un miembro de la corte suprena de Mendoza en Argentina. A partir del siguiente resumen de una setencia de la corte :\\n\\n```\\n{summary_ant}\\n\\n{summary_1}\\n\\n{summary_2}\\n\\n {summary_3}\\n\\n {summary_res}.\\n```\\n\\n\"\n",
    "prompt +=\"Explicar las causas detras de la decision final de la sentencia. Escribe un sumario de la corte en no menos de 250 palabras. Favor de no mencionar:\\n1. Los nombres de las secciones.\\n2. Los nombres de los casos.\\n3. Los nombres de los ministros de la corte.\\n4. Las fechas y la ubicacion de la corte.\\n\\n\"\n",
    "prompt +=\"Cuando escribas el sumario tener en cuenta que este puede ayudar en futura jurisprudencia.\" \n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ab629e-17a8-497d-9357-d9647045b638",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(llm(prompt,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd95b28-7288-4a23-b70b-6b77268a7912",
   "metadata": {},
   "source": [
    "# FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c397a0-8688-43af-a280-bc6ce0c6f014",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create summary (ES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecd2e67e-bafe-4765-bfb7-92b3fb5644e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary_es(rule_file, embedding, llm):\n",
    "    loader = UnstructuredPDFLoader(rule_file)\n",
    "    #index = VectorstoreIndexCreator(embedding=embedding).from_loaders([loader])\n",
    "    #index.vectorstore.delete_collection()\n",
    "    index = VectorstoreIndexCreator(embedding=embedding).from_loaders([loader])\n",
    "    print(\"calculating ant\")\n",
    "    query = \"\"\"\n",
    "    <s>[INST]<<SYS>>\n",
    "    Think after answer. Your answer should be in spanish. Not english.\n",
    "    <</SYS>>\n",
    "    Eres un secretario de la corte suprema de Mendoza en Argentina. \n",
    "    Tienes que escribir un resumen de la seccion 'Antecedentes' de una sentencia de la corte. \n",
    "    Escribe tu respuesta en español y en no mas de 150 palabras:\n",
    "    [/INST]\n",
    "    \"\"\"\n",
    "    summary_ant = (index.query(query,llm=llm))\n",
    "    print(\"calculating 1\")\n",
    "    query = \"\"\"\n",
    "    <s>[INST]<<SYS>>\n",
    "    Think after answer. Your answer should be in spanish. Not in english.\n",
    "    <</SYS>>\n",
    "    Eres un secretario de la corte suprema de Mendoza en Argentina. \n",
    "    Tienes que escribir un resumen de la seccion 'Sobre la primera cuestion' de una sentencia de la corte. \n",
    "    Escribe tu respuesta en español y en no mas de 150 palabras:\n",
    "    [/INST]\n",
    "    \"\"\"\n",
    "\n",
    "    summary_1 = (index.query(query,llm=llm))\n",
    "    print(\"calculating 2\")\n",
    "    query = \"\"\"\n",
    "    <s>[INST]<<SYS>>\n",
    "    Think after answer. Your answer should be in spanish. Not in english.\n",
    "    <</SYS>>\n",
    "    Eres un secretario de la corte suprema de Mendoza en Argentina.\n",
    "    Tienes que escribir un resumen de la seccion 'Sobre la segunda cuestion' de una sentencia de la corte. \n",
    "    Escribe tu respuesta en español y en no mas de 150 palabras:\n",
    "    [/INST]\n",
    "    \"\"\"\n",
    "    summary_2 = (index.query(query,llm=llm))\n",
    "    print(\"calculating 3\")\n",
    "    query = \"\"\"\n",
    "    <s>[INST]<<SYS>>\n",
    "    Think after answer. Your answer should be in spanish. Not in english.\n",
    "    <</SYS>>\n",
    "    Eres un secretario de la corte suprema de Mendoza en Argentina.\n",
    "    Tienes que escribir un resumen de la seccion 'Sobre la tercera cuestion' de una sentencia de la corte. \n",
    "    Escribe tu respuesta en español y en no mas de 150 palabras:\n",
    "    [/INST]\n",
    "    \"\"\"\n",
    "    summary_3 = (index.query(query,llm=llm))\n",
    "    print(\"calculating res\")\n",
    "    query = \"\"\"\n",
    "     <s>[INST]<<SYS>>\n",
    "    Think after answer. Your answer should be in spanish. Not in english.\n",
    "    <</SYS>>\n",
    "    Eres un secretario de la corte suprema de Mendoza en Argentina.\n",
    "    Tienes que escribir un resumen de la seccion 'Resuelve' de una sentencia de la corte. \n",
    "    Escribe tu respuesta en no mas de 150 palabras:\n",
    "    Escribe tu respuesta en español y en no mas de 150 palabras:\n",
    "    [/INST]\n",
    "    \"\"\"    \n",
    "    summary_res = (index.query(query,llm=llm))\n",
    "    \n",
    "    prompt = f\"Eres un oficial perito de la corte suprema de Mendoza en Argentina. A partir del siguiente resumen de una sentencia de la corte :\\n\\n```\\n{summary_ant}\\n\\n{summary_1}\\n\\n{summary_2}\\n\\n {summary_3}\\n\\n {summary_res}.\\n```\\n\\n\"    \n",
    "    prompt +=\"Debes escribir un sumario en donde se expliquen las causas detras de la decision final de la sentencia. Escribir el sumario de la corte en no mas de 700 palabras.\"\n",
    "    prompt +=\"Favor de no mencionar NUNCA:\\n1. Los nombres de las secciones como ser: primera cuestion, segunda cuestion o tercera cuestion.\\n2. Los nombres de los casos.\\n3. Los nombres de los ministros de la corte.\\n4. Las fechas y la ubicacion de la corte.\\n5. La palabra corte\\n\\n\"\n",
    "    prompt +=\"Cuando escribas el sumario tener en cuenta que este puede ayudar en futura jurisprudencia. En caso de disidencia indicar el nombre del  ministro de la corte. \" \n",
    "    #print(prompt)\n",
    "    prompt = f\"\"\"\n",
    "    <s>[INST]<<SYS>>\n",
    "    Think after answer. Your answer should be in spanish. Not in english.\n",
    "    <</SYS>>\n",
    "    {prompt}\n",
    "    Escribe tu respuesta en español y en no mas de 350 palabras:\n",
    "    [/INST]\n",
    "    \"\"\"\n",
    "    index.vectorstore.delete_collection()\n",
    "    print(\"calculating prompt\")\n",
    "    #print(prompt)\n",
    "    res = llm(prompt)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311fb22f-1211-41ba-b069-0883ff45116c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt+=\"\"\" \n",
    "    \n",
    "Sabiendo que un sumario es una descripción resumida de las doctrinas contempladas en la sentencia judicial dado que en ella pueden tratarse diversas cuestiones jurídicas       \n",
    "Presentar un sumario en donde se expliquen las causas detras de la decision final de la sentencia. Escribir el sumario de la corte en no mas de 700 palabras.\"\n",
    "\n",
    "En el sumario incluir:\n",
    "\n",
    "1. Indicar que eventos o circunstancias son centrales para el caso?\n",
    "2. Indicar cómo se valoran las conductas o eventos en el contexto laboral (subjetiva y objetivamente)?\n",
    "3. Indicar como afectan estos hechos la relación entre las partes involucradas (empleador y empleado)?\n",
    "4. Indicar leyes, principios o derechos están en juego (tutela sindical, deber de fidelidad, igualdad de oportunidades, etc.)?\n",
    "5. Indicar qué determinación se hizo respecto a la legalidad de la conducta o evento en cuestión\n",
    "6. Indicar si hubo disidencia entre los jueces\n",
    "\n",
    "En el sumario no mencionar NUNCA:\n",
    "\n",
    "1. Los nombres de las secciones como ser: primera cuestion, segunda cuestion o tercera cuestion.\n",
    "2. Los nombres de los casos.\n",
    "3. Los nombres de los ministros de la corte.\n",
    "4. Las fechas y la ubicacion de la corte.\n",
    "5. La palabra corte\n",
    "6. Los nombres de las personas involucradas.\n",
    "Cuando escribas el sumario tener en cuenta que este puede ayudar en futura jurisprudencia.\n",
    "\n",
    "Limitarse a generar el sumario. No responder Por supuesto.\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed53e5d6-3086-42a4-8c80-d1b82b085347",
   "metadata": {},
   "source": [
    "## Create Summary (EN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7637092-0217-49ac-ad2c-da063529a92b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_summary(rule_file, embedding, llm):\n",
    "    loader = UnstructuredPDFLoader(rule_file)\n",
    "    index = VectorstoreIndexCreator(embedding=embedding).from_loaders([loader])\n",
    "    index.vectorstorae.delete_collection()\n",
    "    index = VectorstoreIndexCreator(embedding=embedding).from_loaders([loader])\n",
    "    query = \"You are a member of the supreme court in Mendoza, Argentina. You have to write a summary of the section named 'Antecedentes' of a particular court ruling . Write your answer in spanish in no less than 150 words:\"\n",
    "    summary_ant = (index.query(query,llm=llm))\n",
    "    query = \"You are a member of the supreme court in Mendoza, Argentina. You have to write a summary of the section named 'Sobre la primera cuestion' of a particular court ruling . Write your answer in spanish in no less than 150 words::\"\n",
    "    summary_1 = (index.query(query,llm=llm))\n",
    "    query = \"You are a member of the supreme court in Mendoza, Argentina. You have to write a summary of the section named 'Sobre la segunda cuestion' of a particular court ruling . Write your answer in spanish in no less than 150 words::\"\n",
    "    summary_2 = (index.query(query,llm=llm))\n",
    "    query = \"You are a member of the supreme court in Mendoza, Argentina. You have to write a summary of the section named 'Sobre la tercera cuestion' of a particular court ruling . Write your answer in spanish in no less than 150 words::\"\n",
    "    summary_3 = (index.query(query,llm=llm))\n",
    "    query = \"You are a member of the supreme court in Mendoza, Argentina. You have to write a summary of the section named 'resuelve' of a particular court ruling . Write your answer in spanish in no less than 150 words::\"\n",
    "    summary_res = (index.query(query,llm=llm))\n",
    "\n",
    "    prompt = f\"You are a member of the supreme court, Argentina. Given the following summary of a particular court ruling:\\n\\n```\\n{summary_ant}\\n\\n{summary_1}\\n\\n{summary_2}\\n\\n {summary_3}\\n\\n {summary_res}.\\n```\\n\\n\"\n",
    "    prompt +=\"Write a court rule summary in spanish in no less than 150 words. Do not mention:\\n1. the name of the the sections.\\n2. the numbers of the cases.\\n3. the names of the ministers of the court.\\n4. dates and court locations..\\n\\n\"\n",
    "    prompt +=\"When writing the summary keep in mind it can help for future jurisprudence. Explain the causes behind the final decision. Translate your answer to spanish:\"\n",
    "    index.vectorstore.delete_collection()\n",
    "    return llm(prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a55fd1-2472-4af7-9be8-d6966d0a4ea7",
   "metadata": {},
   "source": [
    "### Run example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df52b6de-8d30-4e80-86ba-a990799c028d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating ant\n",
      "calculating 1\n",
      "calculating 2\n",
      "calculating 3\n",
      "calculating res\n",
      "calculating prompt\n"
     ]
    }
   ],
   "source": [
    "file_name = \"/root/JurisGPT/rawdata/laboral/sumarios/fallos/10000003368.pdf\"\n",
    "summary = create_summary_es(file_name, embedding = embedding, llm = llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f54b246d-d660-4b62-8ee0-4ed893eee16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " La sentencia final del Superior Tribunal Provincial de Córdoba en re: \"Lopez\" se pronunciará en contra del razonamiento que se pretende, ya cueste fundada con la normativas aplicables. En consequence, la cadánea de los hecho no puede considerarse como un impedimento para la applicación de las leyas de riesgo laborales, ya sea que se trate de la norma de la Ley de Trabajo y Seguridad (ley N° 20.746) o la Ley N°21235. Por otro lado, la LRT (ley de riesigos laborales) y LCT son de applicación general, no pueden limitarse por la cadeña de los eventos. En resumen la ley de la causa es contraría a la doctrina jurisprudencial y debe revisarse.\n"
     ]
    }
   ],
   "source": [
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5e863596",
   "metadata": {},
   "outputs": [],
   "source": [
    "res =llm(summary)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67174b2-12f0-45c3-8bcf-b78c21cd2600",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory_path = \"/root/JurisGPT/data/laboral/qa/\"  \n",
    "name, extension = os.path.splitext(os.path.basename(file_name))\n",
    "summary_filename = f\"{name}_summary.txt\"\n",
    "summary_file_path = os.path.join(output_directory_path, summary_filename)\n",
    "with open(summary_file_path, 'w') as f:\n",
    "    f.write(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd83f15-7ec3-4090-9add-b6ff97fba189",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create summary from dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc34f7a1-2175-49d9-9b96-9201854e7f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary_from_dir(directory_path, output_directory_path, embedding, llm):\n",
    "    import time\n",
    "    # Loop through each file in the directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        # Extract the file extension\n",
    "        name, extension = os.path.splitext(filename)\n",
    "        \n",
    "        # Build the full file path\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        \n",
    "        # Skip directories, only work on PDF files\n",
    "        if os.path.isfile(file_path) and extension.lower() == '.pdf':\n",
    "            print(f'working on {file_path}')\n",
    "            # Generate summary\n",
    "            start_time = time.time()\n",
    "            summary = create_summary_es(file_path, embedding, llm)\n",
    "            stop_time = time.time()\n",
    "            \n",
    "            # Save summary to new file\n",
    "            summary_filename = f\"{name}_summary.txt\"\n",
    "            summary_file_path = os.path.join(output_directory_path, summary_filename)\n",
    "            \n",
    "            with open(summary_file_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(summary)\n",
    "            print(f'created {summary_file_path} in {stop_time - start_time} seconds')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144ad149-3151-4150-ae62-8d6c7775a64c",
   "metadata": {},
   "source": [
    "## Calculate ROUGE metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a6b05f1-88a3-492d-9b42-ecb281871b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from rouge import Rouge\n",
    "\n",
    "def calculate_rouge(system_dir, model_dir, system_filename_pattern, model_filename_pattern):\n",
    "    # Initialize Rouge\n",
    "    rouge = Rouge()\n",
    "    \n",
    "    # Compile the regular expressions for filename patterns\n",
    "    system_re = re.compile(system_filename_pattern)\n",
    "    model_re = re.compile(model_filename_pattern)\n",
    "    \n",
    "    # Initialize storage for scores\n",
    "    all_scores = []\n",
    "\n",
    "    # Loop through the files in the system summaries directory\n",
    "    for system_filename in os.listdir(system_dir):\n",
    "        match = system_re.match(system_filename)\n",
    "        if not match:\n",
    "            continue\n",
    "\n",
    "        # Extract ID\n",
    "        system_id = match.groups()[0]\n",
    "\n",
    "        # Find the corresponding model summary file using ID\n",
    "        model_filename = f\"{system_id}_summary.txt\"\n",
    "        model_path = os.path.join(model_dir, model_filename)\n",
    "\n",
    "        # Check if model summary exists\n",
    "        if not os.path.exists(model_path):\n",
    "            print(f\"Model summary for {system_id} not found. Attempted to open {model_path}\")\n",
    "            continue\n",
    "\n",
    "        \n",
    "\n",
    "        # Check if model summary exists\n",
    "        if not os.path.exists(model_path):\n",
    "            print(f\"Model summary for {system_id} not found.\")\n",
    "            continue\n",
    "\n",
    "        # Read system and model summaries\n",
    "        with open(os.path.join(system_dir, system_filename), 'r', encoding='utf-8') as f:\n",
    "            system_summary = f.read().strip()\n",
    "            system_summary = re.sub('<.*?>', '', system_summary)\n",
    "            #print(system_summary)\n",
    "        \n",
    "        with open(model_path, 'r', encoding='utf-8') as f:\n",
    "            model_summary = f.read().strip()\n",
    "    \n",
    "        # Compute the ROUGE score\n",
    "        score = rouge.get_scores(system_summary, model_summary)[0]\n",
    "        #all_scores.append(score)\n",
    "        all_scores.append({\n",
    "            'system_id': system_id,\n",
    "            'rouge-1': score['rouge-1'],\n",
    "            'rouge-2': score['rouge-2'],\n",
    "            'rouge-l': score.get('rouge-l', {})  # Add this line to include ROUGE-L\n",
    "        })\n",
    "        # Compute the ROUGE score\n",
    "\n",
    "\n",
    "        # Extract ROUGE-1, ROUGE-2, and ROUGE-3 scores\n",
    "        #rouge_1 = score.get('rouge-1', {})\n",
    "        #rouge_2 = score.get('rouge-2', {})\n",
    "       \n",
    "        # Pretty-print scores\n",
    "        #print(f\"ROUGE scores for ID {system_id}:\")\n",
    "        #print(f\"  ROUGE-1: R: {rouge_1.get('r', 'N/A'):.4f}, P: {rouge_1.get('p', 'N/A'):.4f}, F: {rouge_1.get('f', 'N/A'):.4f}\")\n",
    "        #print(f\"  ROUGE-2: R: {rouge_2.get('r', 'N/A'):.4f}, P: {rouge_2.get('p', 'N/A'):.4f}, F: {rouge_2.get('f', 'N/A'):.4f}\")\n",
    "      \n",
    "        \n",
    "        #print(f\"ROUGE score for ID {system_id}: {score}\")\n",
    "\n",
    "    # If you want average scores, you can calculate that here from all_scores.\n",
    "    # ...\n",
    "\n",
    "    return all_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997c8cab-e957-437d-9452-ca0ef1d612e2",
   "metadata": {},
   "source": [
    "## Print ROUGE TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "76070bc1-1dae-4c0c-b3d3-6b406ba10256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # Don't forget to import pandas\n",
    "\n",
    "def print_rouge_table(all_scores):\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    \n",
    "    system_ids = []\n",
    "    metrics = []\n",
    "    rs = []\n",
    "    ps = []\n",
    "    fs = []\n",
    "\n",
    "    # Loop through each dictionary to extract the values\n",
    "    for score_dict in all_scores:\n",
    "        system_id = score_dict['system_id']\n",
    "\n",
    "        for metric, values in score_dict.items():\n",
    "            if metric == 'system_id':\n",
    "                continue  # Skip the system_id, we've already saved it\n",
    "\n",
    "            system_ids.append(system_id)\n",
    "            metrics.append(metric)\n",
    "            rs.append(values['r'])\n",
    "            ps.append(values['p'])\n",
    "            fs.append(values['f'])\n",
    "\n",
    "    # Create the DataFrame\n",
    "    df_long = pd.DataFrame({\n",
    "        'system_id': system_ids,\n",
    "        'metric': metrics,\n",
    "        'r': rs,\n",
    "        'p': ps,\n",
    "        'f': fs\n",
    "    })\n",
    "\n",
    "    return df_long"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7a2c51-b6ee-4405-97ee-5281a277e656",
   "metadata": {
    "tags": []
   },
   "source": [
    "# UTILS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e885c0c4-31c9-40d4-9387-ac5c353121e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Stop LLAMA Jumpstart endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d34763d-9ee2-4da5-b82e-a94cf0d3b8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "aws_region = boto3.Session().region_name\n",
    "endpoint_name = \"jumpstart-dft-meta-textgeneration-llama-2-13b-f\"\n",
    "\n",
    "# Create a low-level SageMaker service client.\n",
    "sagemaker_client = boto3.client('sagemaker', region_name=aws_region)\n",
    "\n",
    "# Delete endpoint\n",
    "sagemaker_client.delete_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348d7eba-5a67-4237-b63b-3b4bbcddb7c1",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec2b1f3-2465-43cb-82b0-c1707d7a1e9b",
   "metadata": {},
   "source": [
    "## Create Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0ebef33f-f5c4-4023-8ddb-724fd77bf462",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"/root/JurisGPT/rawdata/laboral/sumarios/fallos/\"  \n",
    "output_directory_path = \"/root/JurisGPT/data/laboral/qa/\"  \n",
    "create_summary_from_dir(directory_path, output_directory_path, embedding = embedding, llm = llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730628bc-c6bc-4230-9f81-4613da758629",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Calculate ROUGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af048859-a98c-451b-87e1-5afde5b17528",
   "metadata": {},
   "source": [
    "The ROUGE-1 metric is a type of Recall-Oriented Understudy for Gisting Evaluation (ROUGE) score that is commonly used for evaluating the quality of summaries by comparing them to reference summaries. Specifically, ROUGE-1 measures the overlap of unigrams (single words) between the generated summary and the reference summary.\n",
    "\n",
    "The ROUGE-1 score comprises three values:\n",
    "\n",
    "1. **Precision (P)**: This measures the number of overlapping unigrams found in both the generated summary and the reference summary, divided by the total number of unigrams in the generated summary. In essence, precision answers the question: \"Of all the unigrams in the generated summary, how many are in the reference summary?\"\n",
    "   \\[\n",
    "   \\text{Precision} = \\frac{\\text{Number of overlapping unigrams}}{\\text{Total number of unigrams in generated summary}}\n",
    "   \\]\n",
    "\n",
    "2. **Recall (R)**: This measures the number of overlapping unigrams found in both the generated summary and the reference summary, divided by the total number of unigrams in the reference summary. Recall answers the question: \"Of all the unigrams in the reference summary, how many are in the generated summary?\"\n",
    "   \\[\n",
    "   \\text{Recall} = \\frac{\\text{Number of overlapping unigrams}}{\\text{Total number of unigrams in reference summary}}\n",
    "   \\]\n",
    "\n",
    "3. **F1 Score (F)**: This is the harmonic mean of precision and recall and serves as a single number that balances the trade-off between precision and recall.\n",
    "   \\[\n",
    "   \\text{F1 Score} = \\frac{2 \\times \\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "   \\]\n",
    "\n",
    "ROUGE-1 is particularly useful for assessing the quality of extractive summaries, where sentences or phrases are selected from the original text to form a summary. The metric can also be used for abstractive summaries but may not capture the quality of the summary as effectively as when combined with other ROUGE metrics like ROUGE-2 (bigram overlap) or ROUGE-L (longest common subsequence)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00213ec-362d-4965-a2f0-a4a0a5fecec9",
   "metadata": {},
   "source": [
    "# 7B Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0eacb802-e06e-475d-83e5-cb27047f2f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths and patterns\n",
    "system_dir = '/root/JurisGPT/rawdata/laboral/sumarios/'\n",
    "model_dir = '/root/JurisGPT/data/laboral/qa/13b-ft//'\n",
    "system_filename_pattern = r'(\\d+)\\.txt'\n",
    "model_filename_pattern = r'(\\d+)_summary\\.txt'\n",
    "# Calculate ROUGE\n",
    "all_scores = calculate_rouge(system_dir, model_dir, system_filename_pattern, model_filename_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ba758a49-02f3-4248-aa96-d6a79b44f309",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_table = print_rouge_table(all_scores)\n",
    "rouge_table.query(\"metric == 'rouge-1'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "39ae4dec-42ee-410c-9dd4-3b6f9d3cb12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(rouge_table.query(\"metric == 'rouge-1'\")['r'].mean(),\n",
    "rouge_table.query(\"metric == 'rouge-1'\")['r'].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81738e0-37ce-4014-ad16-85638e9e502b",
   "metadata": {},
   "source": [
    "# 13B results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f197ee-c526-4d7b-bbb2-b7d7ef7e0ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths and patterns\n",
    "system_dir = '/root/JurisGPT/rawdata/laboral/sumarios/'\n",
    "model_dir = '/root/JurisGPT/data/laboral/qa/13b/'\n",
    "system_filename_pattern = r'(\\d+)\\.txt'\n",
    "model_filename_pattern = r'(\\d+)_summary\\.txt'\n",
    "# Calculate ROUGE\n",
    "all_scores = calculate_rouge(system_dir, model_dir, system_filename_pattern, model_filename_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729b75f4-f39b-4ee4-bdac-d8eb2da01ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_table = print_rouge_table(all_scores)\n",
    "rouge_table.query(\"metric == 'rouge-1'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b720c08e-7c66-4cb6-853d-a47648a29fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "(rouge_table.query(\"metric == 'rouge-1'\")['r'].mean(),\n",
    "rouge_table.query(\"metric == 'rouge-1'\")['r'].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef9412b-8697-45d1-a9dd-dc4426c9e25a",
   "metadata": {},
   "source": [
    "# 70B results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b195a30b-25c2-43b6-ad46-2334193292dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths and patterns\n",
    "system_dir = '/root/JurisGPT/rawdata/laboral/sumarios/'\n",
    "model_dir = '/root/JurisGPT/data/laboral/qa/70b/'\n",
    "system_filename_pattern = r'(\\d+)\\.txt'\n",
    "model_filename_pattern = r'(\\d+)_summary\\.txt'\n",
    "# Calculate ROUGE\n",
    "all_scores = calculate_rouge(system_dir, model_dir, system_filename_pattern, model_filename_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b33da2-e8ff-4a8c-87bc-8b3e0d730a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_table = print_rouge_table(all_scores)\n",
    "rouge_table.query(\"metric == 'rouge-1'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fe75f0-5fea-4641-a917-af8c448b608c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(rouge_table.query(\"metric == 'rouge-1'\")['r'].mean(),\n",
    "rouge_table.query(\"metric == 'rouge-1'\")['r'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3304710e-e7db-4e63-b878-2adc831be8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm(\"\"\"[INST] Corregir los errores en el siguiente texto¨: \n",
    "    La sentenza recurrida resulta invalidada por la omision de la norma 2.455.7, que establece la obligación de aplicar los intereses moratoriaos. La ausencia de esta determinación es un grave error que puede anular el fallace. La ley establece que los interesos moratorioas se aplican en los casos de despido, cuando el trabajador se encuentra con una enfermeda psicologica que le impide ejercer su trabajo. En este caso, el trabajado presenta una enfermadad psicológica que se manifestó en el año 2018, y que le llevó al despido laboral en el 212. Por tanto, se cumple la condición para aplicar la normas establecidas en la leyes 26.773 y 27.348. La norma establece el interés anual del 3% sobre el monto de la indemización, desde el momento en que se produce el pago. En el caso, la indenmización se produjo en el mes de mayo del 22, por tanto, el interes anual debe ser calculado desde ese momento.\n",
    "    [/INST]\n",
    "    \"\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fd9329-8db9-479f-9478-be5081896594",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 2.0.0 Python 3.10 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/pytorch-2.0.0-gpu-py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
